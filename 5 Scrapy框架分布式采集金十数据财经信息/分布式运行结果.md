### 使用crawl模板的分布式爬虫

- push_task.py（向远程主机推送任务）

  ```python
  import redis
  from datetime import datetime, timedelta
  
  r = redis.Redis(host='43.143.173.241', port=6379, password='123456', db=1, decode_responses=True)
  base_url = 'https://e0430d16720e4211b5e072c26205c890.z3c.jin10.com/get/data?date='
  redis_key = 'jinshishuju:start_urls'
  
  start_date = datetime.strptime("2020-01-01", "%Y-%m-%d")
  end_date = datetime.strptime("2025-05-16", "%Y-%m-%d")
  
  current = start_date
  while current <= end_date:
      date_str = current.strftime("%Y-%m-%d")
      full_url = f"{base_url}{date_str}&category=cj"
      r.lpush(redis_key, full_url)
      print("Pushed:", full_url)
      current += timedelta(days=1)
  ```

- 运行结果

  ![image-20250520075646610](C:\Users\31923\AppData\Roaming\Typora\typora-user-images\image-20250520075646610.png)

  ![image-20250520075714376](C:\Users\31923\AppData\Roaming\Typora\typora-user-images\image-20250520075714376.png)

- jinshishuju.py

  ```python
  import json
  import scrapy
  from scrapy_redis.spiders import RedisSpider
  from experiment.items import JinshishujuItem
  
  
  class JinshishujuSpider(RedisSpider):
      name = "jinshishuju"
      redis_key = "jinshishuju:start_urls"
  
      custom_settings = {
          'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...',
          'ROBOTSTXT_OBEY': False,
          'ITEM_PIPELINES': {
              'experiment.pipelines.MySQLPipeline': 300,
          },
          'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
          'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
          'SCHEDULER_PERSIST': True,
          'REDIS_HOST': 'localhost',
          'REDIS_PORT': 6379,
          'REDIS_PARAMS': {
              'password': '123456',
              'db': 1,
              'decode_responses': False
          },
          'SCHEDULER_QUEUE_CLASS': 'scrapy_redis.queue.SpiderQueue',
          'DOWNLOAD_TIMEOUT': 15,  # 设置请求超时，避免长时间挂起
          'RETRY_TIMES': 3,  # 重试次数
      }
  
      headers = {
          "accept": "application/json, text/plain, */*",
          "origin": "https://rili.jin10.com",
          "referer": "https://rili.jin10.com/",
          "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36",
          "x-app-id": "sKKYe29sFuJaeOCJ",
          "x-version": "2.0"
      }
  
      def start_requests(self):
          while True:
              url = self.server.lpop(self.redis_key)  # self.server 是 Redis 连接实例
              if not url:
                  break
              if isinstance(url, bytes):
                  url = url.decode('utf-8')
              self.logger.info(f"开始请求URL: {url}")
              print('-----------------------------------')
              yield scrapy.Request(url=url, headers=self.headers, callback=self.parse)
  
      def parse(self, response, **kwargs):
          self.logger.info(f"响应状态码: {response.status}，URL: {response.url}")
          if response.status != 200:
              self.logger.warning(f"非200响应，跳过: {response.status}")
              return
          try:
              data = json.loads(response.text)
          except json.JSONDecodeError as e:
              self.logger.error(f"JSON解析失败: {e}，内容片段: {response.text[:200]}")
              return
          data_dict = data.get('data', [])
          if not data_dict:
              self.logger.warning(f"接口未返回数据，URL: {response.url}")
              return
  
          for i in data_dict:
              item = JinshishujuItem()
              item['time'] = i.get('actual_time') or '时间数据为空'
  
              country = i.get('country') or ''
              time_period = i.get('time_period') or ''
              indicator_name = i.get('indicator_name') or ''
              item['data'] = country + time_period + indicator_name or '数据为空'
  
              star_map = {1: '很低', 2: '低', 3: '中', 4: '高', 5: '很高'}
              item['importance'] = star_map.get(i.get('star'), '重要性为空')
  
              item['previous'] = (i.get('previous') + '%') if i.get('previous') else '前值为空'
              item['consensus'] = (i.get('consensus') + '%') if i.get('consensus') else '预测值为空'
              item['actual'] = (i.get('actual') + '%') if i.get('actual') else '公布值为空'
  
              yield item
  ```

- 运行结果

  ![image-20250520084450754](C:\Users\31923\AppData\Roaming\Typora\typora-user-images\image-20250520084450754.png)

  ![image-20250520090549786](C:\Users\31923\AppData\Roaming\Typora\typora-user-images\image-20250520090549786.png)
