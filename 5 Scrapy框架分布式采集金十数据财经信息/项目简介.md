# 项目简介

本项目基于`Scrapy`框架，采用两种方式，分布式爬虫，以及本机采集的方式，分别实现对金十财经网站实时财经信息的高效采集与管理。项目旨在自动化获取包括全球经济数据、重大财经事件、市场行情等多维度的金融信息，为金融分析、投资决策和数据研究提供稳定、实时的数据支持。

本机采集方式爬取效率低，资源利用率高，但采集速度仍然可观，不过金十财经数据量庞大，不建议采取这种方式。

分布式爬虫方式：项目能够大幅提升爬取速度和数据吞吐量，利用消息队列（`Redis`）实现任务调度和节点协调，确保采集任务的高效执行和负载均衡。

## 技术栈

- `Scrapy`框架：用于搭建爬虫项目的核心框架，支持异步抓取、高度可定制、易于扩展。
- `Mysql`数据库：用于持久化存储采集到的财经信息数据，支持结构化查询。
- `Redis`数据库：作为分布式任务调度的消息队列，实现URL去重、任务队列管理、节点间通信等功能。
- `base`以及`crawl`模板：`CrawlSpider`用于处理规则化页面抓取，`BaseSpider`适用于更灵活的定制抓取逻辑。
- `pymysql`包：用于`Python`与`MySQL`数据库之间的数据读写交互。
- `redis`包：`Python`操作`Redis`数据库的官方客户端，用于管理调度任务与状态存储
- `datetime`包：用于循环生成从起始日期到结束日期之间每天的URL请求
- `scrapyd`包：`Scrapy `项目的部署与管理工具，用于将爬虫打包并部署到服务器上，通过 `HTTP `接口进行远程启动、停止和监控爬虫运行状态，支持定时任务调度，适合生产环境下的爬虫调度和自动化管理。
- `gerapy`包：基于 `Scrapyd `的可视化爬虫管理平台，支持图形化配置 `Scrapy` 项目、节点管理、爬虫调度、项目打包与部署等功能，提升分布式爬虫的管理效率，适合团队协作和多节点部署场景

## 工具

- 远程服务器（腾讯云服务器）

- `docker`（方便环境的部署）

  `compose.yaml`

  ```yaml
  version: '3.8'
  
  services:
    mongo:
      image: mongo:latest
      container_name: mongo
      environment:
        MONGO_INITDB_ROOT_USERNAME: root
        MONGO_INITDB_ROOT_PASSWORD: "123456"
      ports:
        - "27017:27017"
      volumes:
        - ./mongo_data:/data/db
      restart: always
  
    redis:
      image: redis:latest
      container_name: redis
      command: redis-server --requirepass "123456"
      ports:
        - "6379:6379"
      volumes:
        - ./redis_data:/data
      restart: always
  
    mysql:
      image: mysql:latest
      container_name: mysql
      environment:
        MYSQL_ROOT_PASSWORD: "123456"
      ports:
        - "3306:3306"
      volumes:
        - ./mysql_data:/var/lib/mysql
      restart: always
  ```

  