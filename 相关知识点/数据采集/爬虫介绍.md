## 作业

```python
# 正则库
import re

# 请求库
import requests

# 解决表格问题的库
import pandas as pd

# 指定url
url = 'https://www.maoyan.com/board'

# 伪装请求头
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# 获取响应
reponse = requests.get(url, headers=headers)

# 用正则解析响应
data = reponse.text

pattern = re.compile(
    r'<dd>.*?'
    r'title="(.*?)".*?'  # 标题
    r'<p class="star">\s*主演：(.*?)\s*</p>.*?'  # 主演
    r'<p class="releasetime">上映时间：(.*?)</p>.*?'  # 上映时间
    r'</dd>', re.S
)

result = pattern.findall(data)

# print(result)

# 将解析后的数据持久化储存
data = pd.DataFrame(result)

# print(data)

data.to_csv('data.csv')

for i in result:
    print(i[0], i[1], i[2])
```



## 爬虫介绍

### 什么是爬虫？

模拟人上网的过程



### 爬虫的基本流程？

1.指定url

2.通过requests模块发起请求

3.获取响应

4.解析响应，得到自己想要的数据

- 解析响应的方法
  - 正则
  - xpath
  - beautifulsoup

5.持久化存储



### 爬虫分类

通用爬虫：抓取网站中所有的内容包括子url

聚焦爬虫：聚焦于某个点抓取数据

增量式爬虫：抓取网站更新的数据，历史不抓取



### 常见的反爬技术

1、机器人协议/robots.txt 君子协议（一般在网站后面输入robots.txt就能查看）

2、身份载体的检测 

- User-agent :Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/133.0.0.0

3、ip封锁：如果该请求频率过快，可能会封锁ip

4、验证码

5、字体加密

6、js混淆

7、登录的算法加密

8、md5

9、sha

10、rsa

11、des/aes



### 反反爬策略

1、UA伪装（对应身份载体的检测 ）

2、使用现有的比较成熟的 ip代理网站 降低下访问的频率（ip封锁，透明代理，普通匿名，高级匿名）

3、使用现有的成熟的验证码识别平台 超级鹰

4、字体加密 --- 找到字体文件

5、算法加密